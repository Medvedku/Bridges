{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://node:prokopcakovamama@xerxes.57jmr.mongodb.net/alfa?retryWrites=true&w=majority\")\n",
    "\n",
    "db = client[\"prod\"]\n",
    "collection = db[\"PRJ-25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of documents\n",
    "total_documents = collection.count_documents({})\n",
    "total_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pier_info = {\n",
    "    0: {\n",
    "        \"UUID\": \"277769444929224\",\n",
    "        \"SN\": 195,\n",
    "        \"Color\": \"16cc62\",\n",
    "        \"Sensors\": {\n",
    "            11: {\"HEX\": \"0x0B\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            12: {\"HEX\": \"0x0C\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            27: {\"HEX\": \"0x1B\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            3:  {\"HEX\": \"0x03\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "        }\n",
    "    },\n",
    "    3: {\n",
    "        \"UUID\": \"124005320765128\",\n",
    "        \"SN\": 193,\n",
    "        \"Color\": \"e65d19\",\n",
    "        \"Sensors\": {\n",
    "            4:  {\"HEX\": \"0x04\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "            8:  {\"HEX\": \"0x08\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "            15: {\"HEX\": \"0x0F\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            17: {\"HEX\": \"0x11\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            21: {\"HEX\": \"0x15\", \"Type\": \"ILeaf\", \"Probes\": {\"pv0\": {\"tare\": 0.120401}, \"pv1\": {\"tare\": -1.477360}, \"pv3\": {\"tare\": 0}}},\n",
    "        }\n",
    "    },\n",
    "    4: {\n",
    "        \"UUID\": \"124005320765128\",\n",
    "        \"SN\": 193,\n",
    "        \"Color\": \"196ee6\",\n",
    "        \"Sensors\": {\n",
    "            26: {\"HEX\": \"0x1A\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "            2:  {\"HEX\": \"0x02\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "            19: {\"HEX\": \"0x13\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            14: {\"HEX\": \"0x0E\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            24: {\"HEX\": \"0x18\", \"Type\": \"ILeaf\", \"Probes\": {\"pv0\": {\"tare\": 1.477902}, \"pv1\": {\"tare\": -1.031515}, \"pv3\": {\"tare\": 0}}},\n",
    "        }\n",
    "    },\n",
    "    5: {\n",
    "        \"UUID\": \"229128940302024\",\n",
    "        \"SN\": 194,\n",
    "        \"Color\": \"8a27a5\",\n",
    "        \"Sensors\": {\n",
    "            1:  {\"HEX\": \"0x01\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "            6:  {\"HEX\": \"0x06\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "            16: {\"HEX\": \"0x10\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            13: {\"HEX\": \"0x0D\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            22: {\"HEX\": \"0x16\", \"Type\": \"ILeaf\", \"Probes\": {\"pv0\": {\"tare\": 2.599761}, \"pv1\": {\"tare\": 0.228347}, \"pv3\": {\"tare\": 0}}},\n",
    "        }\n",
    "    },\n",
    "    6: {\n",
    "        \"UUID\": \"229128940302024\",\n",
    "        \"SN\": 194,\n",
    "        \"Color\": \"c10422\",\n",
    "        \"Sensors\": {\n",
    "            7:  {\"HEX\": \"0x07\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "            9:  {\"HEX\": \"0x09\", \"Type\": \"PLeaf\", \"Probes\": {\"pv0\": {\"tare\": 0}, \"pv1\": {\"tare\": 0}, \"pv3\": {\"tare\": 0}}},\n",
    "            18: {\"HEX\": \"0x12\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            20: {\"HEX\": \"0x14\", \"Type\": \"TLeaf\", \"Probes\": {\"pv1\": {\"tare\": 0}, \"pv2\": {\"tare\": 0}}},\n",
    "            23: {\"HEX\": \"0x17\", \"Type\": \"ILeaf\", \"Probes\": {\"pv0\": {\"tare\": 1.605653}, \"pv1\": {\"tare\": -1.985183}, \"pv3\": {\"tare\": 0}}},\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "# Define the dates\n",
    "date_from = datetime(2025, 2, 15, 0, 0, 0, tzinfo=timezone.utc)\n",
    "date_to = datetime(2025, 6, 15, 0, 0, 0, tzinfo=timezone.utc)\n",
    "\n",
    "# Convert to epoch timestamps\n",
    "epoch_from = int(date_from.timestamp())\n",
    "epoch_to = int(date_to.timestamp())\n",
    "\n",
    "# Print the results\n",
    "print(\"Epoch from:\", epoch_from)\n",
    "print(\"Epoch to:\", epoch_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MongoDB aggregation pipeline\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"time.server.epoch\": {\n",
    "                \"$gte\": epoch_from,\n",
    "                \"$lte\": epoch_to\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\n",
    "            \"time.server.epoch\": 1\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch documents\n",
    "documents = list(collection.aggregate(pipeline))\n",
    "\n",
    "# Initialize DataFrames\n",
    "hub_data = {\n",
    "    \"124005320765128\": [],  # HUB for Piers 03 & 04\n",
    "    \"229128940302024\": [],  # HUB for Piers 05 & 06\n",
    "    \"277769444929224\": []   # HUB for Abutment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through documents and structure data\n",
    "for doc in documents:\n",
    "    uuid = str(doc[\"meta\"][\"uuid\"])  # Convert UUID to string for lookup\n",
    "    timestamp = doc[\"time\"][\"server\"][\"epoch\"]\n",
    "    voltage = doc[\"meta\"][\"power\"][\"battery\"][\"voltage\"]\n",
    "\n",
    "    # Find all piers assigned to this UUID\n",
    "    matching_piers = [p for p, info in pier_info.items()\n",
    "                      if info[\"UUID\"] == uuid]\n",
    "\n",
    "    for pier in matching_piers:  # Iterate through all piers for the UUID\n",
    "        sensor_data = {\"Time\": timestamp, \"Voltage\": voltage}\n",
    "\n",
    "        # Extract sensor values\n",
    "        for sensor_id, sensor_info in pier_info[pier][\"Sensors\"].items():\n",
    "            sensor_id_str = str(sensor_id)  # Ensure sensor_id is a string\n",
    "            sensor_values = doc[\"values\"].get(sensor_id_str)\n",
    "\n",
    "            if sensor_values is None:\n",
    "                print(\n",
    "                    f\"⚠ Warning: Sensor {sensor_id} missing for Pier {pier} in UUID {uuid}\")\n",
    "                continue  # Skip if sensor data is missing\n",
    "\n",
    "            # Store the correct values based on sensor type\n",
    "            if sensor_info[\"Type\"] == \"TLeaf\":\n",
    "                sensor_data[f\"T_{sensor_id}_pv1\"] = sensor_values.get(\n",
    "                    \"pv1\", None)\n",
    "                sensor_data[f\"T_{sensor_id}_pv2\"] = sensor_values.get(\n",
    "                    \"pv2\", None)\n",
    "            elif sensor_info[\"Type\"] == \"PLeaf\":\n",
    "                sensor_data[f\"P_{sensor_id}_pv0\"] = sensor_values.get(\n",
    "                    \"pv0\", None)\n",
    "                sensor_data[f\"P_{sensor_id}_pv1\"] = sensor_values.get(\n",
    "                    \"pv1\", None)\n",
    "                sensor_data[f\"P_{sensor_id}_pv3\"] = sensor_values.get(\n",
    "                    \"pv3\", None)\n",
    "            elif sensor_info[\"Type\"] == \"ILeaf\":\n",
    "                sensor_data[f\"I_{sensor_id}_pv0\"] = sensor_values.get(\n",
    "                    \"pv0\", None)\n",
    "                sensor_data[f\"I_{sensor_id}_pv1\"] = sensor_values.get(\n",
    "                    \"pv1\", None)\n",
    "                sensor_data[f\"I_{sensor_id}_pv3\"] = sensor_values.get(\n",
    "                    \"pv3\", None)\n",
    "\n",
    "        # # Debug: Print stored data\n",
    "        # print(f\"\\n=== Storing Data for Pier {pier} (UUID: {uuid}) ===\")\n",
    "        # print(sensor_data)\n",
    "\n",
    "        # Store data in corresponding HUB\n",
    "        hub_data[uuid].append(sensor_data)\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "df_hub_1 = pd.DataFrame(hub_data[\"124005320765128\"])  # HUB for Piers 03 & 04\n",
    "df_hub_2 = pd.DataFrame(hub_data[\"229128940302024\"])  # HUB for Piers 05 & 06\n",
    "df_hub_3 = pd.DataFrame(hub_data[\"277769444929224\"])  # HUB for Abutment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge duplicate time rows\n",
    "def clean_merged_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the DataFrame by merging duplicate timestamps,\n",
    "    keeping the first non-null value for each column.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df  # Return empty DataFrame if no data\n",
    "\n",
    "    # Merge rows by time, keeping first non-null value\n",
    "    df = df.groupby(\"Time\", as_index=False).first()\n",
    "    return df.sort_values(\"Time\")  # Ensure sorted order\n",
    "\n",
    "\n",
    "# Apply to all HUB dataframes\n",
    "df_hub_1 = clean_merged_data(df_hub_1)\n",
    "df_hub_2 = clean_merged_data(df_hub_2)\n",
    "df_hub_3 = clean_merged_data(df_hub_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hub_1.columns, df_hub_2.columns, df_hub_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert epoch to datetime (UTC) in all three DataFrames\n",
    "for df in [df_hub_1, df_hub_2, df_hub_3]:\n",
    "    if not df.empty:\n",
    "        df[\"Time\"] = pd.to_datetime(df[\"Time\"], unit=\"s\", utc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_voltage_between(df_hub_1, df_hub_2, df_hub_3, from_time, to_time, resample_time=\"2h\"):\n",
    "    # Upravíme časové značky tak, aby boli tz-aware (UTC)\n",
    "    from_time = pd.to_datetime(from_time).tz_localize(\"UTC\")\n",
    "    to_time = pd.to_datetime(to_time).tz_localize(\"UTC\")\n",
    "\n",
    "    # Define colors for each HUB\n",
    "    hub_colors = {\n",
    "        \"124005320765128\": \"#196ee6\",  # SN-193 (Pilier 04)\n",
    "        \"229128940302024\": \"#c10422\",  # SN-194 (Pilier 06)\n",
    "        \"277769444929224\": \"#16cc62\"   # SN-195 (Opora 00)\n",
    "    }\n",
    "\n",
    "    # Copy and prepare data\n",
    "    df_list = [df_hub_1.copy(), df_hub_2.copy(), df_hub_3.copy()]\n",
    "    for df in df_list:\n",
    "        if not df.empty:\n",
    "            df[\"Time\"] = pd.to_datetime(df[\"Time\"], utc=True)\n",
    "            df.set_index(\"Time\", inplace=True)\n",
    "            df.sort_index(inplace=True)\n",
    "\n",
    "    # Resample and reset index\n",
    "    df_hub_1_avg = df_list[0].resample(resample_time).mean().reset_index()\n",
    "    df_hub_2_avg = df_list[1].resample(resample_time).mean().reset_index()\n",
    "    df_hub_3_avg = df_list[2].resample(resample_time).mean().reset_index()\n",
    "\n",
    "    # Filter by time range\n",
    "    df_hub_1_avg = df_hub_1_avg[(df_hub_1_avg[\"Time\"] >= from_time) & (\n",
    "        df_hub_1_avg[\"Time\"] <= to_time)]\n",
    "    df_hub_2_avg = df_hub_2_avg[(df_hub_2_avg[\"Time\"] >= from_time) & (\n",
    "        df_hub_2_avg[\"Time\"] <= to_time)]\n",
    "    df_hub_3_avg = df_hub_3_avg[(df_hub_3_avg[\"Time\"] >= from_time) & (\n",
    "        df_hub_3_avg[\"Time\"] <= to_time)]\n",
    "\n",
    "    # Plotting\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for df, uuid, label in zip([df_hub_1_avg, df_hub_2_avg, df_hub_3_avg],\n",
    "                               [\"124005320765128\", \"229128940302024\",\n",
    "                                   \"277769444929224\"],\n",
    "                               [\"SN-193 (pilier 04)\", \"SN-194 (pilier 06)\", \"SN-195 (opora 00)\"]):\n",
    "        if not df.empty:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df[\"Time\"],\n",
    "                y=df[\"Voltage\"],\n",
    "                mode=\"lines\",\n",
    "                name=label,\n",
    "                line=dict(color=hub_colors[uuid])\n",
    "            ))\n",
    "\n",
    "    # Layout\n",
    "    w_ = 1000\n",
    "    fig.update_layout(\n",
    "        title=\"Napätia batérie HUB-ov\",\n",
    "        xaxis_title=\"Čas (UTC)\",\n",
    "        yaxis_title=\"Napätie [V]\",\n",
    "        legend_title=\"HUB\",\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"left\",\n",
    "            x=0.0\n",
    "        ),\n",
    "        width=w_,\n",
    "        height=(w_ / 8) * 5,\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_voltage_between(df_hub_1, df_hub_2, df_hub_3,\n",
    "                     \"2025-05-01 00:00\", \"2025-06-01 00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_inclinations(df, pier_number, uuid, title, from_time=None, to_time=None):\n",
    "    \"\"\"\n",
    "    Plots inclinations (pv0 and pv1) for a given pier using Plotly.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        pier_number (int): Pier number from pier_info.\n",
    "        uuid (str): UUID of the corresponding HUB.\n",
    "        title (str): Title of the plot.\n",
    "        from_time (str or datetime, optional): Start time for filtering (UTC).\n",
    "        to_time (str or datetime, optional): End time for filtering (UTC).\n",
    "    \"\"\"\n",
    "    if pier_number not in pier_info:\n",
    "        print(f\"Pier {pier_number} not found in pier_info.\")\n",
    "        return\n",
    "\n",
    "    sensor_id = next((sid for sid, info in pier_info[pier_number][\"Sensors\"].items()\n",
    "                      if info[\"Type\"] == \"ILeaf\"), None)\n",
    "    if sensor_id is None:\n",
    "        print(f\"No ILeaf sensor found for Pier {pier_number}.\")\n",
    "        return\n",
    "\n",
    "    col_pv0 = f\"I_{sensor_id}_pv0\"\n",
    "    col_pv1 = f\"I_{sensor_id}_pv1\"\n",
    "\n",
    "    if col_pv0 not in df.columns or col_pv1 not in df.columns:\n",
    "        print(\n",
    "            f\"Missing inclinometer data for Pier {pier_number}. Expected columns: {col_pv0}, {col_pv1}\")\n",
    "        return\n",
    "\n",
    "    # Time filtering\n",
    "    df = df.copy()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], utc=True)\n",
    "\n",
    "    if from_time:\n",
    "        from_time = pd.to_datetime(from_time)\n",
    "        if from_time.tzinfo is None:\n",
    "            from_time = from_time.tz_localize(\"UTC\")\n",
    "        df = df[df[\"Time\"] >= from_time]\n",
    "\n",
    "    if to_time:\n",
    "        to_time = pd.to_datetime(to_time)\n",
    "        if to_time.tzinfo is None:\n",
    "            to_time = to_time.tz_localize(\"UTC\")\n",
    "        df = df[df[\"Time\"] <= to_time]\n",
    "\n",
    "    color = \"#\" + pier_info[pier_number][\"Color\"]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df[\"Time\"],\n",
    "        y=df[col_pv0],\n",
    "        mode=\"lines\",\n",
    "        name=\"Pozitívny trend je náklon v smere toku rieky Váh (na juh)\",\n",
    "        line=dict(color=color)\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df[\"Time\"],\n",
    "        y=df[col_pv1],\n",
    "        mode=\"lines\",\n",
    "        name=\"Pozitívny trend je náklon na Šaľu (na západ)\",\n",
    "        line=dict(color=color, width=2),\n",
    "        opacity=0.5,\n",
    "        yaxis=\"y2\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Čas (UTC)\",\n",
    "        yaxis=dict(\n",
    "            title=\"Náklon kolmo na most (pv0)\",\n",
    "            side=\"left\"\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title=\"Náklon v smere mosta (pv1)\",\n",
    "            overlaying=\"y\",\n",
    "            side=\"right\",\n",
    "            showgrid=False\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"left\",\n",
    "            x=0.00\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=625,\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inclinations for each pier\n",
    "plot_inclinations(df_hub_1, pier_number=3,\n",
    "                  uuid=\"124005320765128\", title=\"Náklon piliera 03\",\n",
    "                  from_time=\"2025-05-01 00:00\", to_time=\"2025-06-01 00:00\")\n",
    "plot_inclinations(df_hub_1, pier_number=4,\n",
    "                  uuid=\"124005320765128\", title=\"Náklon piliera 04\",\n",
    "                  from_time=\"2025-05-01 00:00\", to_time=\"2025-06-01 00:00\")\n",
    "plot_inclinations(df_hub_2, pier_number=5,\n",
    "                  uuid=\"229128940302024\", title=\"Náklon piliera 05\",\n",
    "                  from_time=\"2025-05-01 00:00\", to_time=\"2025-06-01 00:00\")\n",
    "plot_inclinations(df_hub_2, pier_number=6,\n",
    "                  uuid=\"229128940302024\", title=\"Náklon piliera 06\",\n",
    "                  from_time=\"2025-05-01 00:00\", to_time=\"2025-06-01 00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin_inclinations(df, pier_number, title, from_time=None, to_time=None):\n",
    "    if pier_number not in pier_info:\n",
    "        return\n",
    "\n",
    "    sensor_id = next((sid for sid, info in pier_info[pier_number][\"Sensors\"].items()\n",
    "                      if info[\"Type\"] == \"ILeaf\"), None)\n",
    "    if sensor_id is None:\n",
    "        return\n",
    "\n",
    "    col_pv0 = f\"I_{sensor_id}_pv0\"\n",
    "    col_pv1 = f\"I_{sensor_id}_pv1\"\n",
    "    col_pv3 = f\"I_{sensor_id}_pv3\"\n",
    "\n",
    "    df_adj = df.copy()\n",
    "    df_adj[\"Time\"] = pd.to_datetime(df_adj[\"Time\"], utc=True)\n",
    "\n",
    "    if from_time:\n",
    "        from_time = pd.to_datetime(from_time, utc=True)\n",
    "        df_adj = df_adj[df_adj[\"Time\"] >= from_time]\n",
    "    if to_time:\n",
    "        to_time = pd.to_datetime(to_time, utc=True)\n",
    "        df_adj = df_adj[df_adj[\"Time\"] <= to_time]\n",
    "\n",
    "    df_adj[col_pv0] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv0\"][\"tare\"]\n",
    "    df_adj[col_pv1] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv1\"][\"tare\"]\n",
    "    df_adj[col_pv3] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv3\"][\"tare\"]\n",
    "    df_adj[col_pv1] *= -1\n",
    "\n",
    "    df_adj[\"Date\"] = df_adj[\"Time\"].dt.date\n",
    "    color = \"#\" + pier_info[pier_number][\"Color\"]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    legend_added = {\"pv0\": False, \"pv1\": False}\n",
    "\n",
    "    for col, label, opacity, legend_key, marker_symbol in [\n",
    "        (col_pv0, \"+ inklinácia → tok rieky Váh (na juh)\", 1.0, \"pv0\", \"x\"),\n",
    "        (col_pv1, \"+ inklinácia → Trnovec/Váhom (na východ)\", 0.5, \"pv1\", \"circle\")\n",
    "    ]:\n",
    "        for date in sorted(df_adj[\"Date\"].unique()):\n",
    "            daily_data = df_adj[df_adj[\"Date\"] == date]\n",
    "            y = daily_data[col]\n",
    "            median_val = y.median()\n",
    "\n",
    "            fig.add_trace(go.Violin(\n",
    "                x=[str(date)] * len(y),\n",
    "                y=y,\n",
    "                name=label if not legend_added[legend_key] else None,\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                line_color=color,\n",
    "                fillcolor=color,\n",
    "                opacity=opacity,\n",
    "                showlegend=not legend_added[legend_key],\n",
    "                yaxis=\"y\"\n",
    "            ))\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[str(date)],\n",
    "                y=[median_val],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=\"black\", size=8, symbol=marker_symbol),\n",
    "                showlegend=False,\n",
    "                yaxis=\"y\"\n",
    "            ))\n",
    "\n",
    "            legend_added[legend_key] = True\n",
    "\n",
    "    # Add temperature line on secondary axis\n",
    "    temp_series = df_adj.groupby(\"Date\")[col_pv3].mean()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[str(d) for d in temp_series.index],\n",
    "        y=temp_series.values,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"#DDDDDD\", width=2),\n",
    "        name=\"Teplota senzora (priemer)\",\n",
    "        yaxis=\"y2\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Dátum\",\n",
    "        yaxis=dict(\n",
    "            title=\"Náklon [°]\",\n",
    "            side=\"left\"\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title=\"Teplota [°C]\",\n",
    "            overlaying=\"y\",\n",
    "            side=\"right\",\n",
    "            showgrid=False\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"left\",\n",
    "            x=0.00\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=600,\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violin_inclinations(\n",
    "    df=df_hub_1,\n",
    "    pier_number=3,\n",
    "    title=\"Denné rozloženie náklonov – pilier 03\",\n",
    "    from_time=\"2025-05-01\",\n",
    "    to_time=\"2025-05-31\"\n",
    ")\n",
    "\n",
    "plot_violin_inclinations(\n",
    "    df=df_hub_1,\n",
    "    pier_number=4,\n",
    "    title=\"Denné rozloženie náklonov – pilier 04\",\n",
    "    from_time=\"2025-05-01\",\n",
    "    to_time=\"2025-05-31\"\n",
    ")\n",
    "\n",
    "plot_violin_inclinations(\n",
    "    df=df_hub_2,\n",
    "    pier_number=5,\n",
    "    title=\"Denné rozloženie náklonov – pilier 05\",\n",
    "    from_time=\"2025-05-01\",\n",
    "    to_time=\"2025-05-31\"\n",
    ")\n",
    "\n",
    "plot_violin_inclinations(\n",
    "    df=df_hub_2,\n",
    "    pier_number=6,\n",
    "    title=\"Denné rozloženie náklonov – pilier 06\",\n",
    "    from_time=\"2025-05-01\",\n",
    "    to_time=\"2025-05-31\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def compute_trend(df_adj, column):\n",
    "    df_adj[\"Date\"] = df_adj[\"Time\"].dt.date\n",
    "    daily_medians = df_adj.groupby(\"Date\")[column].median().dropna()\n",
    "\n",
    "    if len(daily_medians) < 2:\n",
    "        return None, None, None\n",
    "\n",
    "    days = np.arange(len(daily_medians)).reshape(-1, 1)\n",
    "    values = daily_medians.values.reshape(-1, 1)\n",
    "\n",
    "    model = LinearRegression().fit(days, values)\n",
    "    slope = model.coef_[0][0]\n",
    "    intercept = model.intercept_[0]\n",
    "\n",
    "    return daily_medians.index, model.predict(days).flatten(), slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_candlestick_inclinations(df, pier_number, uuid, title, from_time=None, to_time=None):\n",
    "    \"\"\"\n",
    "    Plots candlestick-style inclinations (pv0 and pv1) for a given pier.\n",
    "    - Uses daily resampling to compute open, high, low, close values.\n",
    "    - Displays pv0 and pv1 fluctuations using Plotly Candlestick.\n",
    "    - Temperature (pv3) is shown on a secondary axis.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        pier_number (int): Pier number from pier_info.\n",
    "        uuid (str): UUID of the corresponding HUB.\n",
    "        title (str): Title of the plot.\n",
    "        from_time (str or datetime, optional): Start time for filtering (UTC).\n",
    "        to_time (str or datetime, optional): End time for filtering (UTC).\n",
    "    \"\"\"\n",
    "    if pier_number not in pier_info:\n",
    "        print(f\"Pier {pier_number} not found in pier_info.\")\n",
    "        return\n",
    "\n",
    "    sensor_id = next((sid for sid, info in pier_info[pier_number][\"Sensors\"].items()\n",
    "                      if info[\"Type\"] == \"ILeaf\"), None)\n",
    "    if sensor_id is None:\n",
    "        print(f\"No ILeaf sensor found for Pier {pier_number}.\")\n",
    "        return\n",
    "\n",
    "    col_pv0 = f\"I_{sensor_id}_pv0\"\n",
    "    col_pv1 = f\"I_{sensor_id}_pv1\"\n",
    "    col_pv3 = f\"I_{sensor_id}_pv3\"  # Temperature\n",
    "\n",
    "    if col_pv0 not in df.columns or col_pv1 not in df.columns or col_pv3 not in df.columns:\n",
    "        print(\n",
    "            f\"Missing inclinometer data for Pier {pier_number}. Expected columns: {col_pv0}, {col_pv1}, {col_pv3}\")\n",
    "        return\n",
    "\n",
    "    df_adj = df.copy()\n",
    "    df_adj[\"Time\"] = pd.to_datetime(df_adj[\"Time\"], utc=True)\n",
    "\n",
    "    # Time filtering\n",
    "    if from_time:\n",
    "        from_time = pd.to_datetime(from_time)\n",
    "        if from_time.tzinfo is None:\n",
    "            from_time = from_time.tz_localize(\"UTC\")\n",
    "        df_adj = df_adj[df_adj[\"Time\"] >= from_time]\n",
    "\n",
    "    if to_time:\n",
    "        to_time = pd.to_datetime(to_time)\n",
    "        if to_time.tzinfo is None:\n",
    "            to_time = to_time.tz_localize(\"UTC\")\n",
    "        df_adj = df_adj[df_adj[\"Time\"] <= to_time]\n",
    "\n",
    "    # Subtract tare values and reverse pv1\n",
    "    df_adj[col_pv0] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv0\"][\"tare\"]\n",
    "    df_adj[col_pv1] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv1\"][\"tare\"]\n",
    "    df_adj[col_pv3] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv3\"][\"tare\"]\n",
    "    df_adj[col_pv1] *= -1\n",
    "\n",
    "    # Define custom aggregation with median (open), max, min, mean (close)\n",
    "    df_daily = df_adj.resample('D', on='Time').agg({\n",
    "        col_pv0: [('open', 'median'), ('high', 'max'), ('low', 'min'), ('close', 'mean')],\n",
    "        col_pv1: [('open', 'median'), ('high', 'max'), ('low', 'min'), ('close', 'mean')],\n",
    "        col_pv3: [('mean', 'mean')]\n",
    "    }).dropna()\n",
    "\n",
    "    # Flatten column MultiIndex\n",
    "    df_daily.columns = ['pv0_open', 'pv0_high', 'pv0_low', 'pv0_close',\n",
    "                        'pv1_open', 'pv1_high', 'pv1_low', 'pv1_close',\n",
    "                        'pv3_mean']\n",
    "\n",
    "\n",
    "    color = \"#\" + pier_info[pier_number][\"Color\"]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=df_daily.index,\n",
    "        open=df_daily['pv0_open'],\n",
    "        high=df_daily['pv0_high'],\n",
    "        low=df_daily['pv0_low'],\n",
    "        close=df_daily['pv0_close'],\n",
    "        name=\"+ inklinácia → tok rieky Váh (na juh)\",\n",
    "        increasing_line_color=color,\n",
    "        decreasing_line_color=color\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=df_daily.index,\n",
    "        open=df_daily['pv1_open'],\n",
    "        high=df_daily['pv1_high'],\n",
    "        low=df_daily['pv1_low'],\n",
    "        close=df_daily['pv1_close'],\n",
    "        name=\"+ inklinácia → Trnovec/Váhom (na východ)\",\n",
    "        increasing_line_color=color,\n",
    "        decreasing_line_color=color,\n",
    "        yaxis=\"y\",\n",
    "        opacity=0.5\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_daily.index,\n",
    "        y=df_daily['pv3_mean'],\n",
    "        mode=\"lines\",\n",
    "        name=\"Teplota senzora (priemer)\",\n",
    "        line=dict(color=\"#CCCCCC\"),\n",
    "        yaxis=\"y2\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Čas (UTC)\",\n",
    "        yaxis=dict(\n",
    "            title=\"Náklon (pv0 & pv1)\",\n",
    "            side=\"left\"\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title=\"Teplota senzora (pv3) [°C] (priemer)\",\n",
    "            overlaying=\"y\",\n",
    "            side=\"right\",\n",
    "            showgrid=False\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"left\",\n",
    "            x=0.00\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=625,\n",
    "        template=\"plotly_white\",\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(visible=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Common time range\n",
    "# from_time = \"2025-04-01 00:00\"\n",
    "# to_time = \"2025-05-01 00:00\"\n",
    "\n",
    "# plot_candlestick_inclinations(\n",
    "#     df_hub_1, pier_number=3, uuid=\"124005320765128\", title=\"Náklon piliera 03\",\n",
    "#     from_time=from_time, to_time=to_time)\n",
    "# plot_candlestick_inclinations(\n",
    "#     df_hub_1, pier_number=4, uuid=\"124005320765128\", title=\"Náklon piliera 04\",\n",
    "#     from_time=from_time, to_time=to_time)\n",
    "# plot_candlestick_inclinations(\n",
    "#     df_hub_2, pier_number=5, uuid=\"229128940302024\", title=\"Náklon piliera 05\",\n",
    "#     from_time=from_time, to_time=to_time)\n",
    "# plot_candlestick_inclinations(\n",
    "#     df_hub_2, pier_number=6, uuid=\"229128940302024\", title=\"Náklon piliera 06\",\n",
    "#     from_time=from_time, to_time=to_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_ohlc_table(df, pier_number):\n",
    "    \"\"\"\n",
    "    Generates a table with OHLC (Open, High, Low, Close) values for pv0 and pv1,\n",
    "    and the average value for pv3, per day.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        pier_number (int): Pier number from pier_info.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table containing the OHLC values.\n",
    "    \"\"\"\n",
    "    if pier_number not in pier_info:\n",
    "        print(f\"Pier {pier_number} not found in pier_info.\")\n",
    "        return None\n",
    "\n",
    "    # Get inclinometer sensor ID (ILeaf) for this pier\n",
    "    sensor_id = next((sid for sid, info in pier_info[pier_number][\"Sensors\"].items()\n",
    "                      if info[\"Type\"] == \"ILeaf\"), None)\n",
    "    if sensor_id is None:\n",
    "        print(f\"No ILeaf sensor found for Pier {pier_number}.\")\n",
    "        return None\n",
    "\n",
    "    # Use sensor ID (not HEX) for column names\n",
    "    col_pv0 = f\"I_{sensor_id}_pv0\"\n",
    "    col_pv1 = f\"I_{sensor_id}_pv1\"\n",
    "    col_pv3 = f\"I_{sensor_id}_pv3\"  # Temperature\n",
    "\n",
    "    # Check if columns exist\n",
    "    if col_pv0 not in df.columns or col_pv1 not in df.columns or col_pv3 not in df.columns:\n",
    "        print(\n",
    "            f\"Missing inclinometer data for Pier {pier_number}. Expected columns: {col_pv0}, {col_pv1}, {col_pv3}\")\n",
    "        return None\n",
    "\n",
    "    # Copy DataFrame to avoid modifying the original\n",
    "    df_adj = df.copy()\n",
    "\n",
    "    # Subtract tare values\n",
    "    df_adj[col_pv0] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv0\"][\"tare\"]\n",
    "    df_adj[col_pv1] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv1\"][\"tare\"]\n",
    "    df_adj[col_pv3] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv3\"][\"tare\"]\n",
    "    df_adj[col_pv1] *= -1  # Reverse direction for pv1\n",
    "\n",
    "    # Compute daily OHLC (Open, High, Low, Close) values for pv0 and pv1, and average for pv3\n",
    "    df_daily = df_adj.resample('D', on='Time').agg({\n",
    "        col_pv0: ['first', 'max', 'min', 'last', 'mean'],\n",
    "        col_pv1: ['first', 'max', 'min', 'last', 'mean'],\n",
    "        col_pv3: 'mean'  # Only daily mean for temperature\n",
    "    }).dropna()\n",
    "\n",
    "    # Rename columns for better readability\n",
    "    df_daily.columns = ['pv0_open', 'pv0_high', 'pv0_low', 'pv0_close', 'pv0_mean',\n",
    "                        'pv1_open', 'pv1_high', 'pv1_low', 'pv1_close', 'pv1_mean',\n",
    "                        'pv3_mean']\n",
    "\n",
    "    # Reset index for display purposes\n",
    "    df_daily.reset_index(inplace=True)\n",
    "    df_daily.rename(columns={'Time': 'Date'}, inplace=True)\n",
    "\n",
    "    return df_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate OHLC tables for all 4 piers\n",
    "df_ohlc_pier3 = generate_ohlc_table(df_hub_1, pier_number=3)\n",
    "df_ohlc_pier4 = generate_ohlc_table(df_hub_1, pier_number=4)\n",
    "df_ohlc_pier5 = generate_ohlc_table(df_hub_2, pier_number=5)\n",
    "df_ohlc_pier6 = generate_ohlc_table(df_hub_2, pier_number=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrames containing only timestamps, P sensors, and T_27 (pv1 & pv2) sensor in df_hub_3\n",
    "df_pressure_1 = df_hub_1[[\n",
    "    'Time'] + [col for col in df_hub_1.columns if col.startswith('P_')]].copy()\n",
    "df_pressure_2 = df_hub_2[[\n",
    "    'Time'] + [col for col in df_hub_2.columns if col.startswith('P_')]].copy()\n",
    "df_pressure_3 = df_hub_3[[\n",
    "    'Time'] + [col for col in df_hub_3.columns if col.startswith('P_')] + ['T_27_pv1', 'T_27_pv2']].copy()\n",
    "\n",
    "# # Display the structure of the new DataFrames\n",
    "df_pressure_1.columns, df_pressure_1.shape, df_pressure_2.columns, df_pressure_2.shape,  df_pressure_3.columns, df_pressure_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Time' is in datetime format and has UTC awareness if needed\n",
    "for df in [df_pressure_1, df_pressure_2, df_pressure_3]:\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], utc=True)\n",
    "    df.set_index(\"Time\", inplace=True)\n",
    "\n",
    "# Resample to 1-hour average\n",
    "df_pressure_1_resampled = df_pressure_1.resample(\"1h\").mean().reset_index()\n",
    "df_pressure_2_resampled = df_pressure_2.resample(\"1h\").mean().reset_index()\n",
    "df_pressure_3_resampled = df_pressure_3.resample(\"1h\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_1_resampled.shape, df_pressure_2_resampled.shape, df_pressure_3_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_merged = df_pressure_1_resampled.merge(\n",
    "    df_pressure_2_resampled, on=\"Time\", how=\"outer\").merge(\n",
    "    df_pressure_3_resampled, on=\"Time\", how=\"outer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_daily_candlesticks_relative(df_pressure_merged, ref_col=\"P_3_pv0\"):\n",
    "    # --- Constants ---\n",
    "    MPG_DENSITY = 1036  # kg/m³\n",
    "    GRAVITY = 9.81      # m/s²\n",
    "    conversion_factor = 1000 / (MPG_DENSITY * GRAVITY)  # Pa → mm\n",
    "\n",
    "    # --- Time window ---\n",
    "    april_start = pd.Timestamp(\"2025-04-01\").tz_localize(\"UTC\")\n",
    "    april_end = pd.Timestamp(\"2025-05-01\").tz_localize(\"UTC\")\n",
    "    drop_start = pd.Timestamp(\"2025-04-11 12:00\").tz_localize(\"UTC\")\n",
    "    drop_end = pd.Timestamp(\"2025-04-13 18:00\").tz_localize(\"UTC\")\n",
    "\n",
    "    # --- Filter and convert time ---\n",
    "    df = df_pressure_merged[\n",
    "        (df_pressure_merged[\"Time\"] >= april_start) &\n",
    "        (df_pressure_merged[\"Time\"] < april_end)\n",
    "    ].copy()\n",
    "    df = df[(df[\"Time\"] < drop_start) | (df[\"Time\"] > drop_end)].copy()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], utc=True)\n",
    "    df.set_index(\"Time\", inplace=True)\n",
    "\n",
    "    # --- Convert pressure to height ---\n",
    "    df_mm = df.copy()\n",
    "    for col in df_mm.columns:\n",
    "        if re.match(r\"P_\\d+_pv0\", col):\n",
    "            df_mm[col] = df_mm[col] * conversion_factor\n",
    "\n",
    "    if ref_col not in df_mm.columns:\n",
    "        raise ValueError(f\"Reference column '{ref_col}' not found!\")\n",
    "\n",
    "    # --- Daily reference mean per day ---\n",
    "    ref_daily_mean = df_mm[ref_col].resample(\"D\").mean()\n",
    "\n",
    "    # --- Aggregate all pv0 sensors ---\n",
    "    for col in df_mm.columns:\n",
    "        match = re.match(r\"P_(\\d+)_pv0\", col)\n",
    "        if not match or col == ref_col:\n",
    "            continue\n",
    "\n",
    "        sensor_id = int(match.group(1))\n",
    "        df_daily = pd.DataFrame({\n",
    "            \"open\": df_mm[col].resample(\"D\").mean() - ref_daily_mean,\n",
    "            \"close\": df_mm[col].resample(\"D\").median() - ref_daily_mean,\n",
    "            \"high\": df_mm[col].resample(\"D\").max() - ref_daily_mean,\n",
    "            \"low\": df_mm[col].resample(\"D\").min() - ref_daily_mean,\n",
    "        }).dropna()\n",
    "\n",
    "        # --- Color from pier_info ---\n",
    "        color = \"#000000\"\n",
    "        for pier_num, pier_data in pier_info.items():\n",
    "            if sensor_id in pier_data[\"Sensors\"]:\n",
    "                color = f\"#{pier_data['Color']}\"\n",
    "                break\n",
    "\n",
    "        # --- Plot ---\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Candlestick(\n",
    "            x=df_daily.index,\n",
    "            open=df_daily[\"open\"],\n",
    "            high=df_daily[\"high\"],\n",
    "            low=df_daily[\"low\"],\n",
    "            close=df_daily[\"close\"],\n",
    "            increasing_line_color=color,\n",
    "            decreasing_line_color=color,\n",
    "            name=col\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Kandlestick: denná výška (relatívne k {ref_col}) – {col}\",\n",
    "            xaxis_title=\"Dátum\",\n",
    "            yaxis_title=\"Rozdiel výšky kvapaliny [mm]\",\n",
    "            width=900,\n",
    "            height=500,\n",
    "            template=\"plotly_white\",\n",
    "            xaxis_rangeslider_visible=False\n",
    "        )\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_daily_candlesticks_relative(df_pressure_merged, ref_col=\"P_3_pv0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_info = {\n",
    "    \"P_8_pv0\":  {\"color\": \"#e65d19\", \"label\": \"Pilier 03 - Juh\", \"HEX\": \"0x08\"},\n",
    "    \"P_4_pv0\":  {\"color\": \"#f09e75\", \"label\": \"Pilier 03 - Sever\", \"HEX\": \"0x04\"},\n",
    "    \"P_2_pv0\":  {\"color\": \"#196ee6\", \"label\": \"Pilier 04 - Juh\", \"HEX\": \"0x02\"},\n",
    "    \"P_26_pv0\": {\"color\": \"#8cb6f2\", \"label\": \"Pilier 04 - Sever\", \"HEX\": \"0x1a\"},\n",
    "    \"P_6_pv0\":  {\"color\": \"#8a27a5\", \"label\": \"Pilier 05 - Juh\", \"HEX\": \"0x06\"},\n",
    "    \"P_1_pv0\":  {\"color\": \"#b97dc9\", \"label\": \"Pilier 05 - Sever\", \"HEX\": \"0x01\"},\n",
    "    \"P_9_pv0\":  {\"color\": \"#c10422\", \"label\": \"Pilier 06 - Juh\", \"HEX\": \"0x09\"},\n",
    "    \"P_7_pv0\":  {\"color\": \"#da6879\", \"label\": \"Pilier 06 - Sever\", \"HEX\": \"0x07\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_daily_candlesticks_relative_with_drift(\n",
    "    df_pressure_merged,\n",
    "    sensor_info,\n",
    "    ref_col=\"P_3_pv0\",\n",
    "    time_range=(\"2025-04-01\", \"2025-04-30\"),\n",
    "    drop_windows=None\n",
    "):\n",
    "    MPG_DENSITY = 1036  # kg/m³\n",
    "    GRAVITY = 9.81      # m/s²\n",
    "    conversion_factor = 1000 / (MPG_DENSITY * GRAVITY)  # Pa → mm\n",
    "\n",
    "    start_ts = pd.Timestamp(time_range[0]).tz_localize(\"UTC\")\n",
    "    end_ts = pd.Timestamp(time_range[1]).tz_localize(\"UTC\")\n",
    "    monitoring_start = df_pressure_merged[\"Time\"].min()\n",
    "\n",
    "    df = df_pressure_merged.copy()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], utc=True)\n",
    "    df.set_index(\"Time\", inplace=True)\n",
    "\n",
    "    # Remove drop windows\n",
    "    if drop_windows:\n",
    "        for drop_start, drop_end in drop_windows:\n",
    "            ds = pd.Timestamp(drop_start).tz_localize(\"UTC\")\n",
    "            de = pd.Timestamp(drop_end).tz_localize(\"UTC\")\n",
    "            df = df[(df.index < ds) | (df.index > de)]\n",
    "\n",
    "    df_mm = df.copy()\n",
    "    for col in df_mm.columns:\n",
    "        if re.match(r\"P_\\d+_pv0\", col):\n",
    "            df_mm[col] = df_mm[col] * conversion_factor\n",
    "\n",
    "    if ref_col not in df_mm.columns:\n",
    "        raise ValueError(f\"Reference column '{ref_col}' not found!\")\n",
    "\n",
    "    tare_end = monitoring_start + pd.Timedelta(days=7)\n",
    "    df_tare = df_mm[(df_mm.index >= monitoring_start)\n",
    "                    & (df_mm.index < tare_end)]\n",
    "    ref_tare = df_tare[ref_col]\n",
    "    ref_daily_mean = df_mm[ref_col].resample(\"D\").mean()\n",
    "\n",
    "    for col, info in sensor_info.items():\n",
    "        if col not in df_mm.columns:\n",
    "            continue\n",
    "\n",
    "        color = info.get(\"color\", \"#000000\")\n",
    "        label = info.get(\"label\", col)\n",
    "        hex_id = info.get(\"HEX\", \"0x??\").lower()\n",
    "\n",
    "        sensor_id_match = re.match(r\"P_(\\d+)_pv0\", col)\n",
    "        if not sensor_id_match:\n",
    "            continue\n",
    "        sensor_id = sensor_id_match.group(1)\n",
    "        temp_col = f\"P_{sensor_id}_pv3\"\n",
    "\n",
    "        tare_series = df_tare[col] - ref_tare\n",
    "        tare_value = tare_series.mean()\n",
    "\n",
    "        df_daily_full = pd.DataFrame({\n",
    "            \"open\": df_mm[col].resample(\"D\").mean() - ref_daily_mean,\n",
    "            \"close\": df_mm[col].resample(\"D\").median() - ref_daily_mean,\n",
    "            \"high\": df_mm[col].resample(\"D\").max() - ref_daily_mean,\n",
    "            \"low\": df_mm[col].resample(\"D\").min() - ref_daily_mean,\n",
    "        }).dropna()\n",
    "\n",
    "        df_daily = df_daily_full[(df_daily_full.index >= start_ts) & (\n",
    "            df_daily_full.index < end_ts)]\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Candlestick(\n",
    "            x=df_daily.index,\n",
    "            open=df_daily[\"open\"],\n",
    "            high=df_daily[\"high\"],\n",
    "            low=df_daily[\"low\"],\n",
    "            close=df_daily[\"close\"],\n",
    "            increasing_line_color=color,\n",
    "            decreasing_line_color=color,\n",
    "            name=label,\n",
    "            yaxis=\"y1\"\n",
    "        ))\n",
    "\n",
    "        for ts, row in df_daily.iterrows():\n",
    "            drift = row[\"open\"] - tare_value\n",
    "            drift_str = f\"{drift:+.1f}\"\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[ts],\n",
    "                y=[row[\"high\"] + 1.5],\n",
    "                mode=\"text\",\n",
    "                text=[drift_str],\n",
    "                textposition=\"top center\",\n",
    "                showlegend=False,\n",
    "                textfont=dict(size=10, color=\"black\"),\n",
    "                yaxis=\"y1\"\n",
    "            ))\n",
    "\n",
    "        if temp_col in df_mm.columns:\n",
    "            df_temp = df_mm[temp_col].resample(\"D\").mean()\n",
    "            df_temp = df_temp[(df_temp.index >= start_ts)\n",
    "                              & (df_temp.index < end_ts)]\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_temp.index,\n",
    "                y=df_temp,\n",
    "                mode=\"lines\",\n",
    "                name=\"Denná teplota senzora\",\n",
    "                line=dict(color=\"#EEEEEE\", width=2),\n",
    "                yaxis=\"y2\",\n",
    "                showlegend=False\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Relatívna výška k referenčnému bodu (opore) – {label}<br><sub>Snímač – {hex_id}</sub>\",\n",
    "            xaxis_title=\"Dátum\",\n",
    "            yaxis=dict(title=\"Rozdiel výšky kvapaliny [mm]\", side=\"left\"),\n",
    "            yaxis2=dict(\n",
    "                title=\"Teplota [°C]\", overlaying=\"y\", side=\"right\", showgrid=False),\n",
    "            width=1000,\n",
    "            height=625,\n",
    "            template=\"plotly_white\",\n",
    "            xaxis_rangeslider_visible=False,\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_daily_candlesticks_relative_with_drift(\n",
    "#     df_pressure_merged,\n",
    "#     sensor_info=sensor_info,\n",
    "#     time_range=(\"2025-04-01\", \"2025-04-30\"),\n",
    "#     drop_windows=[(\"2025-04-11 00:00\", \"2025-04-14 00:00\")]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_daily_candlesticks_relative_with_drift(\n",
    "#     df_pressure_merged,\n",
    "#     sensor_info=sensor_info,\n",
    "#     time_range=(\"2025-03-01\", \"2025-04-01\"),\n",
    "#     # drop_windows=[(\"2025-03-02 00:00\", \"2025-03-05 00:00\"),\n",
    "#     #               (\"2025-04-11 00:00\", \"2025-04-14 00:00\")],\n",
    "#     drop_windows=[(\"2025-03-03 00:00\", \"2025-03-05 00:00\")]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_daily_candlesticks_relative_with_drift(\n",
    "    df_pressure_merged,\n",
    "    sensor_info,\n",
    "    ref_col=\"P_3_pv0\",\n",
    "    time_range=(\"2025-04-01\", \"2025-04-30\"),\n",
    "    drop_windows=None\n",
    "):\n",
    "    MPG_DENSITY = 1036  # kg/m³\n",
    "    GRAVITY = 9.81      # m/s²\n",
    "    conversion_factor = 1000 / (MPG_DENSITY * GRAVITY)  # Pa → mm\n",
    "\n",
    "    start_ts = pd.Timestamp(time_range[0]).tz_localize(\"UTC\")\n",
    "    end_ts = pd.Timestamp(time_range[1]).tz_localize(\"UTC\")\n",
    "    monitoring_start = df_pressure_merged[\"Time\"].min()\n",
    "\n",
    "    df = df_pressure_merged.copy()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], utc=True)\n",
    "    df.set_index(\"Time\", inplace=True)\n",
    "\n",
    "    if drop_windows:\n",
    "        for drop_start, drop_end in drop_windows:\n",
    "            ds = pd.Timestamp(drop_start).tz_localize(\"UTC\")\n",
    "            de = pd.Timestamp(drop_end).tz_localize(\"UTC\")\n",
    "            df = df[(df.index < ds) | (df.index > de)]\n",
    "\n",
    "    df_mm = df.copy()\n",
    "    for col in df_mm.columns:\n",
    "        if re.match(r\"P_\\d+_pv0\", col):\n",
    "            df_mm[col] = df_mm[col] * conversion_factor\n",
    "\n",
    "    if ref_col not in df_mm.columns:\n",
    "        raise ValueError(f\"Reference column '{ref_col}' not found!\")\n",
    "\n",
    "    tare_end = monitoring_start + pd.Timedelta(days=7)\n",
    "    df_tare = df_mm[(df_mm.index >= monitoring_start)\n",
    "                    & (df_mm.index < tare_end)]\n",
    "    ref_tare = df_tare[ref_col]\n",
    "    ref_daily_mean = df_mm[ref_col].resample(\"D\").mean()\n",
    "\n",
    "    for col, info in sensor_info.items():\n",
    "        if col not in df_mm.columns:\n",
    "            continue\n",
    "\n",
    "        color = info.get(\"color\", \"#000000\")\n",
    "        label = info.get(\"label\", col)\n",
    "        hex_id = info.get(\"HEX\", \"0x??\").lower()\n",
    "\n",
    "        sensor_id_match = re.match(r\"P_(\\d+)_pv0\", col)\n",
    "        if not sensor_id_match:\n",
    "            continue\n",
    "        sensor_id = sensor_id_match.group(1)\n",
    "        temp_col = f\"P_{sensor_id}_pv3\"\n",
    "\n",
    "        tare_series = df_tare[col] - ref_tare\n",
    "        tare_value = tare_series.mean()  # <- Back to mean\n",
    "\n",
    "        daily_group = df_mm[[col, ref_col]].resample(\"D\")\n",
    "\n",
    "        df_daily_full = pd.DataFrame({\n",
    "            \"open\": daily_group[col].apply(lambda s: s.quantile(0.25)) - daily_group[ref_col].mean(),\n",
    "            \"close\": daily_group[col].apply(lambda s: s.quantile(0.75)) - daily_group[ref_col].mean(),\n",
    "            \"high\": daily_group[col].max() - daily_group[ref_col].mean(),\n",
    "            \"low\": daily_group[col].min() - daily_group[ref_col].mean(),\n",
    "            # <- Median for X mark\n",
    "            \"median\": daily_group[col].median() - daily_group[ref_col].mean(),\n",
    "        }).dropna()\n",
    "\n",
    "        df_daily = df_daily_full[(df_daily_full.index >= start_ts) & (\n",
    "            df_daily_full.index < end_ts)]\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Candlestick(\n",
    "            x=df_daily.index,\n",
    "            open=df_daily[\"open\"],\n",
    "            high=df_daily[\"high\"],\n",
    "            low=df_daily[\"low\"],\n",
    "            close=df_daily[\"close\"],\n",
    "            increasing_line_color=color,\n",
    "            decreasing_line_color=color,\n",
    "            name=label,\n",
    "            yaxis=\"y1\"\n",
    "        ))\n",
    "\n",
    "        for ts, row in df_daily.iterrows():\n",
    "            drift = (df_mm[col].resample(\"D\").mean().get(ts, None) -\n",
    "                     ref_daily_mean.get(ts, None)) - tare_value\n",
    "            drift_str = f\"{drift:+.1f}\" if pd.notna(drift) else \"\"\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[ts],\n",
    "                y=[row[\"high\"] + 1.5],\n",
    "                mode=\"text\",\n",
    "                text=[drift_str],\n",
    "                textposition=\"top center\",\n",
    "                showlegend=False,\n",
    "                textfont=dict(size=10, color=\"black\"),\n",
    "                yaxis=\"y1\"\n",
    "            ))\n",
    "\n",
    "        # Add median as X mark\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_daily.index,\n",
    "            y=df_daily[\"median\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(symbol=\"x\", size=8, color=\"black\"),\n",
    "            name=\"Medián\",\n",
    "            yaxis=\"y1\",\n",
    "            showlegend=False\n",
    "        ))\n",
    "\n",
    "        if temp_col in df_mm.columns:\n",
    "            df_temp = df_mm[temp_col].resample(\"D\").mean()\n",
    "            df_temp = df_temp[(df_temp.index >= start_ts)\n",
    "                              & (df_temp.index < end_ts)]\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_temp.index,\n",
    "                y=df_temp,\n",
    "                mode=\"lines\",\n",
    "                name=\"Denná teplota senzora\",\n",
    "                line=dict(color=\"#EEEEEE\", width=2),\n",
    "                yaxis=\"y2\",\n",
    "                showlegend=False\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Relatívna výška k referenčnému bodu (opore) – {label}<br><sub>Snímač – {hex_id}</sub>\",\n",
    "            xaxis_title=\"Dátum\",\n",
    "            yaxis=dict(title=\"Rozdiel výšky kvapaliny [mm]\", side=\"left\"),\n",
    "            yaxis2=dict(\n",
    "                title=\"Teplota [°C]\", overlaying=\"y\", side=\"right\", showgrid=False),\n",
    "            width=1000,\n",
    "            height=625,\n",
    "            template=\"plotly_white\",\n",
    "            xaxis_rangeslider_visible=False,\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daily_candlesticks_relative_with_drift(\n",
    "    df_pressure_merged,\n",
    "    sensor_info=sensor_info,\n",
    "    time_range=(\"2025-05-01\", \"2025-05-31\"),\n",
    "    # drop_windows=[(\"2025-04-11 00:00\", \"2025-04-14 00:00\")]\n",
    "    drop_windows=[(\"2025-05-01 00:00\", \"2025-05-03 00:00\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def compute_trend(daily_medians):\n",
    "    if len(daily_medians) < 2:\n",
    "        return None, None\n",
    "    X = np.arange(len(daily_medians)).reshape(-1, 1)\n",
    "    y = daily_medians.values.reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    slope = model.coef_[0][0]\n",
    "    return slope, model.intercept_[0]\n",
    "\n",
    "\n",
    "def prepare_adjusted_inclination_df(df, pier_number, from_time, to_time):\n",
    "    if pier_number not in pier_info:\n",
    "        return None, None, None\n",
    "\n",
    "    sensor_id = next((sid for sid, info in pier_info[pier_number][\"Sensors\"].items()\n",
    "                      if info[\"Type\"] == \"ILeaf\"), None)\n",
    "    if sensor_id is None:\n",
    "        return None, None, None\n",
    "\n",
    "    col_pv0 = f\"I_{sensor_id}_pv0\"\n",
    "    col_pv1 = f\"I_{sensor_id}_pv1\"\n",
    "    col_pv3 = f\"I_{sensor_id}_pv3\"\n",
    "\n",
    "    df_adj = df.copy()\n",
    "    df_adj[\"Time\"] = pd.to_datetime(df_adj[\"Time\"], utc=True)\n",
    "    df_adj = df_adj[(df_adj[\"Time\"] >= pd.to_datetime(from_time, utc=True)) &\n",
    "                    (df_adj[\"Time\"] <= pd.to_datetime(to_time, utc=True))]\n",
    "\n",
    "    df_adj[col_pv0] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv0\"][\"tare\"]\n",
    "    df_adj[col_pv1] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv1\"][\"tare\"]\n",
    "    df_adj[col_pv3] -= pier_info[pier_number][\"Sensors\"][sensor_id][\"Probes\"][\"pv3\"][\"tare\"]\n",
    "    df_adj[col_pv1] *= -1\n",
    "\n",
    "    df_adj[\"Date\"] = df_adj[\"Time\"].dt.date\n",
    "    return df_adj, col_pv0, col_pv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_time = \"2025-05-01\"\n",
    "to_time = \"2025-05-31\"\n",
    "\n",
    "for pier_number in sorted(pier_info):\n",
    "    df_source = df_hub_1 if pier_number in [3, 4] else df_hub_2\n",
    "\n",
    "    df_adj, col_pv0, col_pv1 = prepare_adjusted_inclination_df(\n",
    "        df_source, pier_number, from_time, to_time)\n",
    "    if df_adj is None:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n📌 Pilier {pier_number:02d} – Apríl 2025\")\n",
    "    for col, name in [(col_pv0, \"pv0\"), (col_pv1, \"pv1\")]:\n",
    "        daily_medians = df_adj.groupby(\"Date\")[col].median()\n",
    "\n",
    "        mean_val = df_adj[col].mean()\n",
    "        median_val = df_adj[col].median()\n",
    "        std_val = df_adj[col].std()\n",
    "        slope, intercept = compute_trend(daily_medians)\n",
    "        delta = daily_medians.iloc[-1] - \\\n",
    "            daily_medians.iloc[0] if len(daily_medians) >= 2 else None\n",
    "\n",
    "        trend_symbol = \"⬈\" if slope and slope > 0 else (\n",
    "            \"⬊\" if slope and slope < 0 else \"→\")\n",
    "\n",
    "        print(f\"  {name}:\")\n",
    "        print(f\"    - Priemer: {mean_val:+.3f}°\")\n",
    "        print(f\"    - Medián:  {median_val:+.3f}°\")\n",
    "        print(f\"    - Std dev: {std_val:.3f}°\")\n",
    "        if slope is not None:\n",
    "            print(f\"    - Trend:   {slope:+.4f}°/deň {trend_symbol}\")\n",
    "        if delta is not None:\n",
    "            print(f\"    - Δ medzi 1. a 31. májom: {delta:+.3f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def summarize_candlestick_stats(df_pressure_merged, sensor_info, ref_col=\"P_3_pv0\", time_range=(\"2025-04-01\", \"2025-04-30\"), drop_windows=None):\n",
    "    MPG_DENSITY = 1036\n",
    "    GRAVITY = 9.81\n",
    "    conversion_factor = 1000 / (MPG_DENSITY * GRAVITY)\n",
    "\n",
    "    start_ts = pd.Timestamp(time_range[0]).tz_localize(\"UTC\")\n",
    "    end_ts = pd.Timestamp(time_range[1]).tz_localize(\"UTC\")\n",
    "    monitoring_start = df_pressure_merged[\"Time\"].min()\n",
    "\n",
    "    df = df_pressure_merged.copy()\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], utc=True)\n",
    "    df.set_index(\"Time\", inplace=True)\n",
    "\n",
    "    if drop_windows:\n",
    "        for drop_start, drop_end in drop_windows:\n",
    "            ds = pd.Timestamp(drop_start).tz_localize(\"UTC\")\n",
    "            de = pd.Timestamp(drop_end).tz_localize(\"UTC\")\n",
    "            df = df[(df.index < ds) | (df.index > de)]\n",
    "\n",
    "    df_mm = df.copy()\n",
    "    for col in df_mm.columns:\n",
    "        if re.match(r\"P_\\d+_pv0\", col):\n",
    "            df_mm[col] = df_mm[col] * conversion_factor\n",
    "\n",
    "    if ref_col not in df_mm.columns:\n",
    "        raise ValueError(f\"Reference column '{ref_col}' not found!\")\n",
    "\n",
    "    tare_end = monitoring_start + pd.Timedelta(days=7)\n",
    "    df_tare = df_mm[(df_mm.index >= monitoring_start)\n",
    "                    & (df_mm.index < tare_end)]\n",
    "    ref_tare = df_tare[ref_col]\n",
    "    ref_daily_mean = df_mm[ref_col].resample(\"D\").mean()\n",
    "\n",
    "    for col, info in sensor_info.items():\n",
    "        if col not in df_mm.columns:\n",
    "            continue\n",
    "\n",
    "        label = info.get(\"label\", col)\n",
    "        hex_id = info.get(\"HEX\", \"0x??\").lower()\n",
    "\n",
    "        sensor_id_match = re.match(r\"P_(\\d+)_pv0\", col)\n",
    "        if not sensor_id_match:\n",
    "            continue\n",
    "\n",
    "        tare_series = df_tare[col] - ref_tare\n",
    "        tare_value = tare_series.mean()\n",
    "\n",
    "        daily_group = df_mm[[col, ref_col]].resample(\"D\")\n",
    "\n",
    "        df_daily_full = pd.DataFrame({\n",
    "            \"open\": daily_group[col].apply(lambda s: s.quantile(0.25)) - daily_group[ref_col].mean(),\n",
    "            \"close\": daily_group[col].apply(lambda s: s.quantile(0.75)) - daily_group[ref_col].mean(),\n",
    "            \"high\": daily_group[col].max() - daily_group[ref_col].mean(),\n",
    "            \"low\": daily_group[col].min() - daily_group[ref_col].mean(),\n",
    "            \"median\": daily_group[col].median() - daily_group[ref_col].mean(),\n",
    "        }).dropna()\n",
    "\n",
    "        df_daily = df_daily_full[(df_daily_full.index >= start_ts) & (\n",
    "            df_daily_full.index < end_ts)]\n",
    "\n",
    "        if df_daily.empty:\n",
    "            print(f\"\\n📌 Sensor {label} ({hex_id}): No data in range\")\n",
    "            continue\n",
    "\n",
    "        mean_val = df_daily[\"median\"].mean()\n",
    "        median_val = df_daily[\"median\"].median()\n",
    "        std_val = df_daily[\"median\"].std()\n",
    "\n",
    "        # Linear trend\n",
    "        X = np.arange(len(df_daily)).reshape(-1, 1)\n",
    "        y = df_daily[\"median\"].values.reshape(-1, 1)\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        slope = model.coef_[0][0]\n",
    "        trend_symbol = \"⬈\" if slope > 0 else (\"⬊\" if slope < 0 else \"→\")\n",
    "\n",
    "        delta = df_daily[\"median\"].iloc[-1] - \\\n",
    "            df_daily[\"median\"].iloc[0] if len(df_daily) >= 2 else None\n",
    "\n",
    "        # Mean drift\n",
    "        drift_series = (df_mm[col].resample(\n",
    "            \"D\").mean() - ref_daily_mean) - tare_value\n",
    "        drift_mean = drift_series.loc[df_daily.index].mean()\n",
    "\n",
    "        print(f\"\\n📌 Sensor {label} ({hex_id}) – Apríl 2025\")\n",
    "        print(f\"  - Priemer mediánov: {mean_val:+.2f} mm\")\n",
    "        print(f\"  - Medián mediánov: {median_val:+.2f} mm\")\n",
    "        print(f\"  - Std dev mediánov: {std_val:.3f} mm\")\n",
    "        print(f\"  - Trend: {slope:+.4f} mm/deň {trend_symbol}\")\n",
    "        if delta is not None:\n",
    "            print(f\"  - Δ medzi 1. a 31. máj: {delta:+.3f} mm\")\n",
    "        print(f\"  - Priemerný drift: {drift_mean:+.3f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_candlestick_stats(\n",
    "    df_pressure_merged=df_pressure_merged,\n",
    "    sensor_info=sensor_info,\n",
    "    ref_col=\"P_3_pv0\",\n",
    "    time_range=(\"2025-05-01\", \"2025-05-31\"),\n",
    "    drop_windows=[(\"2025-04-28 00:00\", \"2025-05-03 00:00\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vymazanie niektorých riadkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start=\"2025-04-01\", end=\"2025-04-07\", freq=\"1D\")\n",
    "\n",
    "data = []\n",
    "for date in dates:\n",
    "    samples = np.random.normal(\n",
    "        loc=100 + np.sin(date.dayofyear / 10) * 10, scale=5, size=50)\n",
    "    for value in samples:\n",
    "        data.append({\"Date\": date, \"Value\": value})\n",
    "\n",
    "df_violin = pd.DataFrame(data)\n",
    "\n",
    "# Create violin plot\n",
    "fig = go.Figure()\n",
    "for date in df_violin[\"Date\"].unique():\n",
    "    fig.add_trace(go.Violin(\n",
    "        y=df_violin[df_violin[\"Date\"] == date][\"Value\"],\n",
    "        name=pd.to_datetime(date).strftime(\"%Y-%m-%d\"),\n",
    "        box_visible=True,\n",
    "        meanline_visible=True,\n",
    "        line_color=\"blue\",\n",
    "        fillcolor=\"lightblue\",\n",
    "        opacity=0.6\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Violin Plot of Synthetic Sensor Data (April 2025)\",\n",
    "    yaxis_title=\"Sensor Value\",\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the time range to delete\n",
    "# start_time = pd.Timestamp(\"2025-02-28 14:00\", tz=\"UTC\")\n",
    "# end_time = pd.Timestamp(\"2025-03-04 14:00\", tz=\"UTC\")\n",
    "\n",
    "# # Filter out rows in the given time range\n",
    "# df_pressure_1 = df_pressure_1[(df_pressure_1[\"Time\"] < start_time) | (\n",
    "#     df_pressure_1[\"Time\"] > end_time)]\n",
    "# df_pressure_2 = df_pressure_2[(df_pressure_2[\"Time\"] < start_time) | (\n",
    "#     df_pressure_2[\"Time\"] > end_time)]\n",
    "# df_pressure_3 = df_pressure_3[(df_pressure_3[\"Time\"] < start_time) | (\n",
    "#     df_pressure_3[\"Time\"] > end_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retain only values between 00:00 and 04:00 each day (2 hours before & after 2 AM)\n",
    "# df_pressure_1 = df_pressure_1[df_pressure_1[\"Time\"].dt.hour.between(0, 4)]\n",
    "# df_pressure_2 = df_pressure_2[df_pressure_2[\"Time\"].dt.hour.between(0, 4)]\n",
    "# df_pressure_3 = df_pressure_3[df_pressure_3[\"Time\"].dt.hour.between(0, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in each DataFrame\n",
    "nan_counts_1 = df_pressure_1.isna().sum().sum()\n",
    "nan_counts_2 = df_pressure_2.isna().sum().sum()\n",
    "nan_counts_3 = df_pressure_3.isna().sum().sum()\n",
    "\n",
    "# Print results\n",
    "print(f\"Total NaN values in df_pressure_1: {nan_counts_1}\")\n",
    "print(f\"Total NaN values in df_pressure_2: {nan_counts_2}\")\n",
    "print(f\"Total NaN values in df_pressure_3: {nan_counts_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove timezone from Time column\n",
    "# df_pressure_1[\"Time\"] = df_pressure_1[\"Time\"].dt.tz_localize(None)\n",
    "# df_pressure_2[\"Time\"] = df_pressure_2[\"Time\"].dt.tz_localize(None)\n",
    "# df_pressure_3[\"Time\"] = df_pressure_3[\"Time\"].dt.tz_localize(None)\n",
    "\n",
    "# # Save DataFrames to Excel\n",
    "# df_pressure_1.to_excel(\"df_pressure_1.xlsx\", index=False)\n",
    "# df_pressure_2.to_excel(\"df_pressure_2.xlsx\", index=False)\n",
    "# df_pressure_3.to_excel(\"df_pressure_3.xlsx\", index=False)\n",
    "\n",
    "# print(\"Excel files saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to 1-hour mean but drop rows that contain NaN (introduced by resampling)\n",
    "df_pressure_1_resampled = df_pressure_1.resample(\n",
    "    '1h', on='Time').mean().dropna()\n",
    "df_pressure_2_resampled = df_pressure_2.resample(\n",
    "    '1h', on='Time').mean().dropna()\n",
    "df_pressure_3_resampled = df_pressure_3.resample(\n",
    "    '1h', on='Time').mean().dropna()\n",
    "\n",
    "# Reset index to clean up DataFrame structure\n",
    "df_pressure_1_resampled = df_pressure_1_resampled.reset_index()\n",
    "df_pressure_2_resampled = df_pressure_2_resampled.reset_index()\n",
    "df_pressure_3_resampled = df_pressure_3_resampled.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save resampled DataFrames to CSV\n",
    "# df_pressure_1_resampled.to_csv(\"df_pressure_1_resampled.csv\", index=False)\n",
    "# df_pressure_2_resampled.to_csv(\"df_pressure_2_resampled.csv\", index=False)\n",
    "# df_pressure_3_resampled.to_csv(\"df_pressure_3_resampled.csv\", index=False)\n",
    "\n",
    "# print(\"CSV files saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_merged = df_pressure_1_resampled.merge(df_pressure_2_resampled, on=\"Time\", how=\"outer\") \\\n",
    "    .merge(df_pressure_3_resampled, on=\"Time\", how=\"outer\")\n",
    "\n",
    "df_pressure_merged.sort_values(\"Time\", inplace=True)\n",
    "\n",
    "# Use ffill directly (forward fill)\n",
    "df_pressure_merged = df_pressure_merged.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_merged.to_excel(\"df_pressure_merged.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pressure_merged[\"Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pressure_merged.to_csv(\"df_pressure_merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample by day, calculating the mean for each day\n",
    "df_pressure_daily = df_pressure_merged.resample('D', on='Time').mean()\n",
    "\n",
    "# # Drop NaNs\n",
    "# df_pressure_daily = df_pressure_daily.dropna()\n",
    "\n",
    "# Reset index to keep the \"Time\" column\n",
    "df_pressure_daily = df_pressure_daily.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reference sensor for liquid column height\n",
    "ref_sensor = \"P_3_pv0\"\n",
    "\n",
    "# Create a new DataFrame for settlement/heave calculations\n",
    "df_settlement = df_pressure_daily.copy()\n",
    "\n",
    "# Subtract reference sensor (P_3_pv0) from all other P.pv0 sensors\n",
    "for col in df_settlement.columns:\n",
    "    if col.startswith(\"P_\") and col.endswith(\"_pv0\") and col != ref_sensor:\n",
    "        df_settlement[col] -= df_settlement[ref_sensor]\n",
    "\n",
    "# Drop the reference sensor column itself\n",
    "df_settlement = df_settlement.drop(columns=[ref_sensor])\n",
    "\n",
    "# Ensure temperature sensors are not included\n",
    "df_settlement = df_settlement.drop(columns=[\n",
    "                                   col for col in df_settlement.columns if col.startswith(\"T_\")], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Define colors for each sensor\n",
    "sensor_colors = {\n",
    "    \"P_4_pv0\": \"#f09e75\",\n",
    "    \"P_8_pv0\": \"#e65d19\",\n",
    "    \"P_26_pv0\": \"#8cb6f2\",\n",
    "    \"P_2_pv0\": \"#196ee6\",\n",
    "    \"P_1_pv0\": \"#b97dc9\",\n",
    "    \"P_6_pv0\": \"#8a27a5\",\n",
    "    \"P_7_pv0\": \"#da6879\",\n",
    "    \"P_9_pv0\": \"#c10422\",\n",
    "}\n",
    "\n",
    "# Add traces for each sensor\n",
    "for col in df_settlement.columns:\n",
    "    if col.startswith(\"P_\") and col.endswith(\"_pv0\"):  # Only plot P.pv0 sensors\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_settlement[\"Time\"],\n",
    "            y=df_settlement[col],\n",
    "            mode=\"lines+markers\",\n",
    "            name=col.replace(\"_pv0\", \"\"),  # Simplify legend names\n",
    "            # Default to black if missing\n",
    "            line=dict(color=sensor_colors.get(col, \"#000000\"))\n",
    "        ))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Heave/Settlement of Piers (Relative to Reference Sensor P_3_pv0)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Settlement [m] (Relative to Reference Sensor)\",\n",
    "    legend_title=\"Pressure Sensors\",\n",
    "    template=\"plotly_white\",\n",
    "    width=1000,\n",
    "    height=625  # 8:5 aspect ratio\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion factor for pure Monopropylene Glycol (MPG)\n",
    "MPG_DENSITY = 1036  # kg/m³\n",
    "GRAVITY = 9.81  # m/s²\n",
    "\n",
    "# Convert pressure (Pa) to mm of MPG column height\n",
    "df_pressure_merged_mm = df_pressure_daily.copy()\n",
    "for col in df_pressure_daily.columns:\n",
    "    # Only convert pv0 (liquid column height)\n",
    "    if col.startswith(\"P_\") and \"_pv0\" in col:\n",
    "        df_pressure_merged_mm[col] = df_pressure_daily[col] / \\\n",
    "            (MPG_DENSITY * GRAVITY) * 1000  # Convert to mm\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Define colors for each sensor\n",
    "sensor_colors = {\n",
    "    \"P_4_pv0\": \"#f09e75\",\n",
    "    \"P_8_pv0\": \"#e65d19\",\n",
    "    \"P_26_pv0\": \"#8cb6f2\",\n",
    "    \"P_2_pv0\": \"#196ee6\",\n",
    "    \"P_1_pv0\": \"#b97dc9\",\n",
    "    \"P_6_pv0\": \"#8a27a5\",\n",
    "    \"P_7_pv0\": \"#da6879\",\n",
    "    \"P_9_pv0\": \"#c10422\",\n",
    "}\n",
    "\n",
    "# Subtract reference sensor (P_3_pv0) from all other sensors\n",
    "for col in df_pressure_merged_mm.columns:\n",
    "    if col.startswith(\"P_\") and \"_pv0\" in col and col != \"P_3_pv0\":\n",
    "        adjusted_col = f\"{col}_adjusted\"\n",
    "        df_pressure_merged_mm[adjusted_col] = df_pressure_merged_mm[col] - \\\n",
    "            df_pressure_merged_mm[\"P_3_pv0\"]\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_pressure_merged_mm[\"Time\"],\n",
    "            y=df_pressure_merged_mm[adjusted_col],\n",
    "            mode=\"lines\",\n",
    "            name=col.replace(\"_pv0\", \"\").replace(\"P_\", \"Pier \"),\n",
    "            # Default to black if color not defined\n",
    "            line=dict(color=sensor_colors.get(col, \"#000000\"))\n",
    "        ))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Výšková zmena pilierov (podľa výšky kvapaliny v mm)\",\n",
    "    xaxis_title=\"Čas (UTC)\",\n",
    "    yaxis_title=\"Zmena výšky kvapaliny (mm)\",\n",
    "    legend_title=\"Senzory\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Conversion factor for pure Monopropylene Glycol (MPG)\n",
    "MPG_DENSITY = 1036  # kg/m³\n",
    "GRAVITY = 9.81  # m/s²\n",
    "\n",
    "# Convert pressure (Pa) to mm of MPG column height\n",
    "df_pressure_merged_mm = df_pressure_daily.copy()\n",
    "for col in df_pressure_daily.columns:\n",
    "    # Only convert pv0 (liquid column height)\n",
    "    if col.startswith(\"P_\") and \"_pv0\" in col:\n",
    "        df_pressure_merged_mm[col] = df_pressure_daily[col] / \\\n",
    "            (MPG_DENSITY * GRAVITY) * 1000  # Convert to mm\n",
    "\n",
    "# Compute mean temperature from T_27_pv1 and T_27_pv2\n",
    "df_pressure_merged_mm[\"T_27_avg\"] = df_pressure_merged_mm[[\n",
    "    \"T_27_pv1\", \"T_27_pv2\"]].mean(axis=1)\n",
    "\n",
    "# Tare values: Subtract the first recorded value from each series\n",
    "for col in df_pressure_merged_mm.columns:\n",
    "    if col.startswith(\"P_\") and \"_pv0\" in col:\n",
    "        # Subtract first value from the entire column\n",
    "        df_pressure_merged_mm[col] -= df_pressure_merged_mm[col].iloc[0]\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Define colors and labels for each sensor\n",
    "sensor_info = {\n",
    "    \"P_4_pv0\": {\"color\": \"#f09e75\", \"label\": \"Pier 03 - N\"},\n",
    "    \"P_8_pv0\": {\"color\": \"#e65d19\", \"label\": \"Pier 03 - S\"},\n",
    "    \"P_26_pv0\": {\"color\": \"#8cb6f2\", \"label\": \"Pier 04 - N\"},\n",
    "    \"P_2_pv0\": {\"color\": \"#196ee6\", \"label\": \"Pier 04 - S\"},\n",
    "    \"P_1_pv0\": {\"color\": \"#b97dc9\", \"label\": \"Pier 05 - N\"},\n",
    "    \"P_6_pv0\": {\"color\": \"#8a27a5\", \"label\": \"Pier 05 - S\"},\n",
    "    \"P_7_pv0\": {\"color\": \"#da6879\", \"label\": \"Pier 06 - N\"},\n",
    "    \"P_9_pv0\": {\"color\": \"#c10422\", \"label\": \"Pier 06 - S\"},\n",
    "}\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Subtract reference sensor (P_3_pv0) from all other sensors\n",
    "for col in df_pressure_merged_mm.columns:\n",
    "    if col.startswith(\"P_\") and \"_pv0\" in col and col != \"P_3_pv0\":\n",
    "        adjusted_col = f\"{col}_adjusted\"\n",
    "        df_pressure_merged_mm[adjusted_col] = df_pressure_merged_mm[col] - \\\n",
    "            df_pressure_merged_mm[\"P_3_pv0\"]\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_pressure_merged_mm[\"Time\"],\n",
    "            y=df_pressure_merged_mm[adjusted_col],\n",
    "            mode=\"lines+markers\",\n",
    "            name=sensor_info[col][\"label\"],  # Assigning correct label\n",
    "            line=dict(color=sensor_info[col][\"color\"], width=2),\n",
    "            marker=dict(size=5)\n",
    "        ))\n",
    "\n",
    "# Plot mean temperature (T_27_avg) on secondary y-axis\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_pressure_merged_mm[\"Time\"],\n",
    "    y=df_pressure_merged_mm[\"T_27_avg\"],\n",
    "    mode=\"lines\",\n",
    "    name=\"Teplota\",\n",
    "    # line=dict(color=\"#CCCCCC\", width=2, dash=\"dot\"),\n",
    "    line=dict(color=\"#CCCCCC\", width=2),\n",
    "    yaxis=\"y2\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Výšková zmena pilierov (podľa výšky kvapaliny v mm, tarené hodnoty)\",\n",
    "    xaxis_title=\"Čas (UTC)\",\n",
    "    yaxis=dict(\n",
    "        title=\"Tarená výška kvapaliny (mm)\",\n",
    "        side=\"left\"\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=\"Teplota (°C)\",\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\",\n",
    "        showgrid=False\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation=\"v\",  # Vertical legend\n",
    "        yanchor=\"middle\",\n",
    "        y=0.825,  # Center legend vertically\n",
    "        xanchor=\"left\",\n",
    "        x=1.02  # Move legend to the right of the plot\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=625,\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Conversion factor for pure Monopropylene Glycol (MPG)\n",
    "MPG_DENSITY = 1036  # kg/m³\n",
    "GRAVITY = 9.81  # m/s²\n",
    "\n",
    "# Define colors and labels for each sensor\n",
    "sensor_info = {\n",
    "    \"P_8_pv0\": {\"color\": \"#e65d19\", \"label\": \"Pier 03 - S\"},\n",
    "    \"P_4_pv0\": {\"color\": \"#f09e75\", \"label\": \"Pier 03 - N\"},\n",
    "    \"P_2_pv0\": {\"color\": \"#196ee6\", \"label\": \"Pier 04 - S\"},\n",
    "    \"P_26_pv0\": {\"color\": \"#8cb6f2\", \"label\": \"Pier 04 - N\"},\n",
    "    \"P_6_pv0\": {\"color\": \"#8a27a5\", \"label\": \"Pier 05 - S\"},\n",
    "    \"P_1_pv0\": {\"color\": \"#b97dc9\", \"label\": \"Pier 05 - N\"},\n",
    "    \"P_9_pv0\": {\"color\": \"#c10422\", \"label\": \"Pier 06 - S\"},\n",
    "    \"P_7_pv0\": {\"color\": \"#da6879\", \"label\": \"Pier 06 - N\"},\n",
    "}\n",
    "\n",
    "def plot_pressure_sensors(df_pressure_daily, main_sensor, transparency=0.3, marker_size=7, main_line_width=4):\n",
    "    \"\"\"\n",
    "    Plots adjusted and tared pressure sensor values in mm of MPG column height.\n",
    "    \n",
    "    Parameters:\n",
    "        df_pressure_daily (pd.DataFrame): DataFrame containing pressure data.\n",
    "        main_sensor (str): The primary sensor to be fully plotted.\n",
    "        transparency (float): Transparency level (0-1) for secondary sensors.\n",
    "        marker_size (int): Size of the markers for the main sensor.\n",
    "        main_line_width (int): Width of the main sensor's plot line.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert pressure (Pa) to mm of MPG column height\n",
    "    df_pressure_merged_mm = df_pressure_daily.copy()\n",
    "    for col in df_pressure_daily.columns:\n",
    "        if col.startswith(\"P_\") and \"_pv0\" in col:\n",
    "            df_pressure_merged_mm[col] = df_pressure_daily[col] / \\\n",
    "                (MPG_DENSITY * GRAVITY) * 1000  # Convert to mm\n",
    "\n",
    "    # Compute mean temperature from T_27_pv1 and T_27_pv2\n",
    "    df_pressure_merged_mm[\"T_27_avg\"] = df_pressure_merged_mm[[\n",
    "        \"T_27_pv1\", \"T_27_pv2\"]].mean(axis=1)\n",
    "\n",
    "    # Tare values: Subtract the first recorded value from each series\n",
    "    for col in df_pressure_merged_mm.columns:\n",
    "        if col.startswith(\"P_\") and \"_pv0\" in col:\n",
    "            df_pressure_merged_mm[col] -= df_pressure_merged_mm[col].iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Create Plotly figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Subtract reference sensor (P_3_pv0) from all other sensors\n",
    "    for col in df_pressure_merged_mm.columns:\n",
    "        if col.startswith(\"P_\") and \"_pv0\" in col and col != \"P_3_pv0\":\n",
    "            adjusted_col = f\"{col}_adjusted\"\n",
    "            df_pressure_merged_mm[adjusted_col] = df_pressure_merged_mm[col] - \\\n",
    "                df_pressure_merged_mm[\"P_3_pv0\"]\n",
    "\n",
    "            # Check if this is the main sensor or secondary sensor\n",
    "            is_main_sensor = col == main_sensor\n",
    "            opacity = 1.0 if is_main_sensor else transparency\n",
    "            line_width = main_line_width if is_main_sensor else 2\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_pressure_merged_mm[\"Time\"],\n",
    "                y=df_pressure_merged_mm[adjusted_col],\n",
    "                mode=\"lines+markers\" if is_main_sensor else \"lines\",\n",
    "                name=sensor_info[col][\"label\"],  # Assigning correct label\n",
    "                line=dict(color=sensor_info[col][\"color\"],\n",
    "                          width=line_width, dash=\"solid\"),\n",
    "                marker=dict(size=marker_size) if is_main_sensor else None,\n",
    "                opacity=opacity\n",
    "            ))\n",
    "\n",
    "            # Add value labels with background box (only for main sensor)\n",
    "            if is_main_sensor:\n",
    "                # Reduce clutter\n",
    "                for i in range(0, len(df_pressure_merged_mm), max(1, len(df_pressure_merged_mm) // 10)):\n",
    "                    fig.add_annotation(\n",
    "                        x=df_pressure_merged_mm[\"Time\"].iloc[i],\n",
    "                        y=df_pressure_merged_mm[adjusted_col].iloc[i],\n",
    "                        text=f\"{df_pressure_merged_mm[adjusted_col].iloc[i]:.1f}\",\n",
    "                        showarrow=False,\n",
    "                        font=dict(size=10, color=\"black\"),\n",
    "                        # Background box for value\n",
    "                        bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "                        bordercolor=sensor_info[col][\"color\"],  # Border color\n",
    "                        borderwidth=1,\n",
    "                        yshift=10\n",
    "                    )\n",
    "\n",
    "    # Plot mean temperature (T_27_avg) on secondary y-axis\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_pressure_merged_mm[\"Time\"],\n",
    "        y=df_pressure_merged_mm[\"T_27_avg\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Teplota\",\n",
    "        line=dict(color=\"#CCCCCC\", width=2),\n",
    "        yaxis=\"y2\"\n",
    "    ))\n",
    "\n",
    "    # Customize layout with secondary y-axis\n",
    "    fig.update_layout(\n",
    "        title=f\"Výšková zmena piliera ({sensor_info[main_sensor]['label']})\",\n",
    "        xaxis_title=\"Čas (UTC)\",\n",
    "        yaxis=dict(\n",
    "            title=\"Tarená výška kvapaliny (mm)\",\n",
    "            side=\"left\"\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title=\"Teplota (°C)\",\n",
    "            overlaying=\"y\",\n",
    "            side=\"right\",\n",
    "            showgrid=False\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"middle\",\n",
    "            y=0.825,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=625,\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Generate plots for all 8 sensors with 30% transparency, marker size 7, and main line width 4\n",
    "for sensor in sensor_info.keys():\n",
    "    plot_pressure_sensors(df_pressure_daily, main_sensor=sensor,\n",
    "                          transparency=0.25, marker_size=10, main_line_width=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bridges_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
